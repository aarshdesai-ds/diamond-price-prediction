# ðŸ’Ž Diamond Price Prediction using Multiple Linear Regression

This project predicts the price of diamonds based on their physical and quality characteristics using an end-to-end **machine learning regression pipeline**. It includes data preprocessing, feature engineering, multicollinearity handling, and thorough model evaluation â€” making it a clean and interpretable example of a real-world regression problem.

---

## ðŸ“¦ Dataset

- **Source**: [Kaggle - Diamonds Dataset](https://www.kaggle.com/datasets/shivam2503/diamonds)
- **Target Variable**: `price` (in USD)
- **Features**:
  - **Carat** (weight)
  - **Cut**, **Color**, **Clarity** (quality-based categorical variables)
  - **Depth**, **Table** (percent measurements)
  - **x**, **y**, **z** (dimensions in mm)

---

## ðŸ§  ML Pipeline Overview

### ðŸ§¹ Data Preprocessing
- Dropped redundant columns like `Unnamed: 0`
- Converted categorical features (`cut`, `color`, `clarity`) into **ordinal encodings** based on domain hierarchy
- No missing values were found â€” data was clean

### ðŸ“Š Exploratory Data Analysis (EDA)
- Used **boxplots** to analyze how `price` varies with `cut`, `color`, and `clarity`
- Created **scatter plots** to explore relationships between numeric features and price
- Plotted a **probability density curve** of price to examine its distribution

---

## ðŸŒ¡ï¸ Multicollinearity Handling

- A **correlation heatmap** revealed very high correlation (r > 0.95) between `carat`, `x`, `y`, and `z`
- To avoid multicollinearity and coefficient instability:
  - **Dropped `x`, `y`, and `z`**
  - Retained only `carat` as the representative size feature
- Verified feature independence with **Variance Inflation Factor (VIF)** â€” retained only features with **VIF < 10**

---

## ðŸ“ Modeling & Evaluation

### ðŸ” Linear Regression (Scikit-learn)
- Trained a model on the cleaned and filtered dataset
- Used **RÂ²**, **RMSE**, and **MAE** to assess performance

| Dataset | RÂ² Score | RMSE (USD) | MAE (USD) |
|---------|----------|------------|-----------|
| Train   | 0.902    | 1251.96    | 865.61    |
| Test    | 0.902    | 1235.86    | 859.14    |

âœ”ï¸ **Consistent train/test performance**  
âœ”ï¸ **High RÂ²** and low error indicate a **strong and generalizable model**

---

## ðŸ“‰ Residual Analysis

- Histograms of residuals showed errors were **normally distributed around zero**
- Scatter plots of errors vs actual price revealed **no major bias**, though slightly higher variance at high price range â€” typical of real-world data

---

## ðŸ§¾ Key Insights

- **`carat` is the strongest predictor** of price â€” retains nearly all the signal from dimensions
- Dropping multicollinear features improved **model stability** without reducing accuracy
- The model is **simple, interpretable, and effective**

---

---

## ðŸš€ How to Run

1. Clone this repository  
   `git clone https://github.com/<your-username>/diamond-price-prediction.git`
2. Launch the notebook  
   `jupyter notebook DiamondPricePrediction.ipynb`
3. Run all cells to reproduce the workflow and results

---

## ðŸ“š Tools Used

- Python 3
- Pandas, NumPy
- Seaborn, Matplotlib
- Scikit-learn
- statsmodels (VIF)

---






